{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "leagues = {\n",
    "    \"Premier League\": \"https://www.oddsportal.com/football/england/premier-league/\",\n",
    "    \"Ligue 1\": \"https://www.oddsportal.com/football/france/ligue-1/\",\n",
    "    \"Bundesliga\": \"https://www.oddsportal.com/football/germany/bundesliga/\",\n",
    "    \"Serie A\": \"https://www.oddsportal.com/football/italy/serie-a/\",\n",
    "    \"LaLiga\": \"https://www.oddsportal.com/football/spain/laliga/\",\n",
    "    \"Ligue 1\" : \"https://www.oddsportal.com/football/france/ligue-1/\",\n",
    "    \"Eredivisie\" : \"https://www.oddsportal.com/football/netherlands/eredivisie/\" }\n",
    "\n",
    "leagues2 = {\n",
    "    \"Premier League\": \"https://www.oddsportal.com/football/england/premier-league/\"}\n",
    "\n",
    "odds_pages = {\n",
    "    \"1X2FT\" : \"#1X2;2\",\n",
    "    \"1X2H1\" : \"##1X2;3\",\n",
    "    \"1X2H2\" : \"##1X2;4\",\n",
    "    \"DCFT\" : \"#double;2\",\n",
    "    \"DCH1\" : \"#double;3\",\n",
    "    \"DCH2\" : \"#double;4\",\n",
    "    \"DNBFT\" : \"#dnb;2\",\n",
    "    \"DNBH1\" : \"#dnb;3\",\n",
    "    \"DNBH2\" : \"#dnb;4\",\n",
    "    \"HTFT\" : \"#ht-ft;2\",\n",
    "    \"BTSFT\" : \"#bts;2\",\n",
    "    \"BTSH1\" : \"#bts;3\",\n",
    "    \"BTSH2\" : \"#bts;4\",\n",
    "    \"OUFT\" : \"#over-under;2\",\n",
    "    \"OUH1\" : \"#over-under;3\",\n",
    "    \"OUH2\" : \"#over-under;4\",\n",
    "    \"CSFT\" : \"#cs;2\",\n",
    "    \"CSH1\" : \"#cs;3\",\n",
    "    \"CSH2\" : \"#cs;4\",\n",
    "    \"AHFT\" : \"#ah;2\",\n",
    "    \"AHH1\" : \"#ah;3\",\n",
    "    \"AHH2\" : \"#ah;4\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GETTING THE UPCOMING GAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upcoming_games(leagues):\n",
    "    chrome_driver_path = 'C:/Users/devon/Desktop/Projects/NQ Project/chromedriver.exe'\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    \n",
    "    driver = uc.Chrome(options=chrome_options)    \n",
    "    game_data = []\n",
    "\n",
    "    for league, url in leagues2.items():\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        scripts = soup.find_all(\"script\", type=\"application/ld+json\")\n",
    "\n",
    "        for script in scripts:\n",
    "            try:\n",
    "                data = json.loads(script.string)\n",
    "                if data.get(\"@type\") == \"SportsEvent\":\n",
    "                    game_data.append({\n",
    "                        \"Match\" : data['name'],\n",
    "                        \"Date\" : data['startDate'],\n",
    "                        \"Venue\" : data['location']['name'],\n",
    "                        \"URL\": data[\"url\"]\n",
    "                    })\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "    game_data = pd.DataFrame(game_data)\n",
    "    driver.quit()\n",
    "    return game_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Historical Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historic_games(leagues, no_previous_yrs=12):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "    driver = uc.Chrome(options=chrome_options)\n",
    "\n",
    "    game_data = []\n",
    "\n",
    "    for league, url in leagues.items():\n",
    "        driver.get(url + \"results/\")\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        seasons = soup.find_all(\"option\")\n",
    "        season_links = [option[\"value\"] for option in seasons if \"value\" in option.attrs]\n",
    "        season_links = season_links[:no_previous_yrs]\n",
    "\n",
    "        print(season_links)\n",
    "\n",
    "        for link in season_links:\n",
    "            print(f'Navigating to season: {link}')\n",
    "            driver.get(link)\n",
    "            \n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"pagination-link\"))\n",
    "            )\n",
    "            \n",
    "            driver.execute_script(\"window.scrollBy(1, window.innerHeight);\")\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            raw_pages = soup.find_all(\"a\", class_=\"pagination-link\")\n",
    "            if raw_pages:\n",
    "                pages = [link[\"data-number\"] for link in raw_pages if \"data-number\" in link.attrs]\n",
    "            else:\n",
    "                pages = []\n",
    "\n",
    "            print(f'Pages found: {pages}')\n",
    "            \n",
    "            for page in pages:\n",
    "                print(f\"Scraping page {page}\")\n",
    "                \n",
    "                page_url = link if page == 1 else f\"{link}#/page/{page}/\"\n",
    "                driver.get(page_url)\n",
    "\n",
    "                WebDriverWait(driver, 4).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"pagination-link\"))\n",
    "            )\n",
    "                \n",
    "                driver.execute_script(\"window.scrollBy(1, window.innerHeight);\")\n",
    "\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                \n",
    "                games = soup.find_all('div', class_=\"border-black-borders border-b border-l border-r hover:bg-[#f9e9cc]\")\n",
    "\n",
    "                for game_row in games: \n",
    "                    # Extract game URL\n",
    "                    game_url = game_row.find('a', href=True)\n",
    "                    game_url = game_url['href'] if game_url else \"No URL\"\n",
    "                    \n",
    "                    # Extract teams (e.g., Arsenal vs Manchester City)\n",
    "                    teams = game_row.find_all('p', class_='participant-name')\n",
    "                    if len(teams) == 2:\n",
    "                        game = f\"{teams[0].get_text(strip=True)} - {teams[1].get_text(strip=True)}\"\n",
    "                    else:\n",
    "                        game = \"No Teams Found\"\n",
    "                    \n",
    "                    # Append extracted information to the list\n",
    "                    game_data.append({\n",
    "                        'League' : league,\n",
    "                        'Game': game,\n",
    "                        'URL': f\"https://www.oddsportal.com{game_url}\"\n",
    "                    })\n",
    "\n",
    "    df = pd.DataFrame(game_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET 1X2 TYPE ODDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1x2_odds(url, title, ext, max_retries=100):\n",
    "    \n",
    "    attempt = 0\n",
    "    average_odds = [{f'{title}_1' : ['-'],\n",
    "                    f'{title}_X' : ['-'],\n",
    "                    f'{title}_2' : ['-']}]\n",
    "\n",
    "    while attempt < max_retries:\n",
    "        \n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"chrome-version=132\")\n",
    "        \n",
    "        driver = uc.Chrome(options=chrome_options)\n",
    "        driver.get(url + ext)\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//p[text()='Average']\"))\n",
    "            )\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            average_section = soup.find(\"p\", class_=\"height-content\", string=\"Average\")\n",
    "\n",
    "            if average_section:\n",
    "                parent_div = average_section.find_parent(\"div\", class_=\"border-black-borders\")\n",
    "                next_siblings = parent_div.find_all(\"div\", class_=\"border-black-borders\")\n",
    "                average_odds = [sibling.find(\"p\", class_=\"height-content\").text.strip() for sibling in next_siblings]\n",
    "                average_odds = [{f'{title}_1' : average_odds[0],\n",
    "                                 f'{title}_X' : average_odds[1],\n",
    "                                 f'{title}_2' : average_odds[2]}]\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {attempt + 1}: {title}\")\n",
    "            attempt += 1\n",
    "            \n",
    "            if attempt < max_retries:\n",
    "                print(f\"Retrying... ({attempt}/{max_retries})\")\n",
    "                driver.quit()\n",
    "            else:\n",
    "                print(\"Max retries reached. Returning default values.\")\n",
    "\n",
    "    driver.quit()\n",
    "    return average_odds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET 1,2 ODDS TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1_2_odds(url, title, ext, max_retries=100):\n",
    "    \n",
    "    attempt = 0\n",
    "    average_odds = ['-'] * 2\n",
    "\n",
    "    while attempt < max_retries:\n",
    "        \n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"chrome-version=132\")\n",
    "\n",
    "        driver = uc.Chrome(options=chrome_options)\n",
    "        driver.get(url + ext)\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//p[text()='Average']\"))\n",
    "            )\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            average_section = soup.find(\"p\", class_=\"height-content\", string=\"Average\")\n",
    "\n",
    "            if average_section:\n",
    "                parent_div = average_section.find_parent(\"div\", class_=\"border-black-borders\")\n",
    "                next_siblings = parent_div.find_all(\"div\", class_=\"border-black-borders\")\n",
    "                average_odds = [sibling.find(\"p\", class_=\"height-content\").text.strip() for sibling in next_siblings]\n",
    "                average_odds = [{f'{title}_1' : average_odds[0],\n",
    "                                 f'{title}_2' : average_odds[1]}]\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {attempt + 1}: {title}\")\n",
    "            attempt += 1\n",
    "            \n",
    "            if attempt < max_retries:\n",
    "                print(f\"Retrying... ({attempt}/{max_retries})\")\n",
    "                driver.quit()\n",
    "            else:\n",
    "                print(\"Max retries reached. Returning default values.\")\n",
    "\n",
    "    driver.quit()\n",
    "    return average_odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET HALFTIME/FULLTIME ODDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HTFT(url, ext='#ht-ft;2', max_tries=100):\n",
    "    \n",
    "    attempt = 0\n",
    "\n",
    "    while attempt < max_tries:\n",
    "\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"chrome-version=132\")\n",
    "\n",
    "        driver = uc.Chrome(options=chrome_options)\n",
    "        driver.get(url + ext)\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//p[contains(@class, 'height-content')]\"))\n",
    "            )\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            odds_elements = soup.find_all(\"div\", class_='flex h-9 text-xs max-sm:h-auto')\n",
    "            odds_list = [element.find(\"p\", class_=\"height-content\").text.strip() for element in odds_elements]\n",
    "\n",
    "            average_odds = [{'H_H' :odds_list[0],\n",
    "                            'H_D' :odds_list[1],\n",
    "                            'H_A' :odds_list[2],\n",
    "                            'D_H' :odds_list[3],\n",
    "                            'D_D' :odds_list[4],\n",
    "                            'D_A' :odds_list[5],\n",
    "                            'A_H' :odds_list[6],\n",
    "                            'A_D' :odds_list[7],\n",
    "                            'A_A' :odds_list[8]}]\n",
    "            \n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {attempt + 1}: {ext}\")\n",
    "            attempt += 1\n",
    "            \n",
    "            if attempt < max_tries:\n",
    "                print(f\"Retrying... ({attempt}/{max_tries})\")\n",
    "                driver.quit()  \n",
    "                 \n",
    "            else:\n",
    "                print(\"Max retries reached. Returning default values.\")\n",
    "    \n",
    "    driver.quit()\n",
    "    return average_odds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET OVER/UNDER ODDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OU(url, ext, title, max_retries=100):\n",
    "\n",
    "    all_row_data = []\n",
    "    attempt = 0\n",
    "\n",
    "    while attempt < max_retries:\n",
    "        \n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"chrome-version=132\")\n",
    "\n",
    "        driver = uc.Chrome(options=chrome_options)\n",
    "        driver.get(url + ext)\n",
    "        try:\n",
    "\n",
    "            WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[contains(@class, 'relative flex flex-col')]\"))\n",
    "            )\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            over_under_elements = soup.find_all(\"div\", class_=\"relative flex flex-col\")\n",
    "            \n",
    "            row_data = {}\n",
    "\n",
    "            for element in over_under_elements:\n",
    "                over_under_text = element.find(\"div\", class_=\"flex w-full items-center justify-start pl-3 font-bold text-[#2F2F2F]\").find_all(\"p\")\n",
    "                over_under = over_under_text[0].text.strip()\n",
    "                odds_containers = element.find_all(\"div\", class_=\"flex-center border-black-main min-w-[60px] max-w-[60px] flex-col gap-1 border-l border-opacity-10\")\n",
    "                \n",
    "                yes_odds = odds_containers[0].find(\"p\").text.strip()\n",
    "                no_odds = odds_containers[1].find(\"p\").text.strip()\n",
    "\n",
    "                row_data[f\"{over_under}_{title}_Over\"] = yes_odds\n",
    "                row_data[f\"{over_under}_{title}_Under\"] = no_odds\n",
    "\n",
    "            all_row_data.append(row_data)\n",
    "\n",
    "            if not all_row_data or not row_data:\n",
    "                print(f\"Warning: No OU or odds found on attempt {attempt + 1}. Retrying...\")\n",
    "                attempt += 1\n",
    "                driver.quit()\n",
    "                continue\n",
    "\n",
    "            return all_row_data\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {attempt + 1}: {ext}\")\n",
    "            attempt += 1\n",
    "            driver.quit()\n",
    "            \n",
    "            if attempt + 1 < max_retries:\n",
    "                print(f\"Retrying... ({attempt + 1}/{max_retries})\")\n",
    "                driver.quit()\n",
    "\n",
    "            else:\n",
    "                print(f\"Max retries reached. Moving to the next URL.\")\n",
    "                break\n",
    "    \n",
    "    driver.quit()\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET CORRECT SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CS(url, ext, title, max_retries=100):\n",
    "\n",
    "    attempt = 0\n",
    "\n",
    "    while attempt < max_retries:\n",
    "    \n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"chrome-version=132\")\n",
    "\n",
    "        driver = uc.Chrome(options=chrome_options)\n",
    "        driver.get(url + ext)\n",
    "        try:\n",
    "\n",
    "            WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[contains(@class, 'relative flex flex-col')]\"))\n",
    "            )\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            \n",
    "            cs = [f\"CS{title}_\" + score.find(\"p\").text for score in soup.find_all('div', 'flex w-full items-center justify-start pl-3 font-bold text-[#2F2F2F]')]\n",
    "            odds = [odd.text for odd in soup.find_all('div', class_='flex h-9 text-xs max-sm:h-auto')]\n",
    "\n",
    "            if not cs or not odds:\n",
    "                print(f\"Warning: No CS or odds found on attempt {attempt + 1}. Retrying...\")\n",
    "                attempt += 1\n",
    "                driver.quit()\n",
    "                continue\n",
    "\n",
    "            table = dict(zip(cs, odds))\n",
    "\n",
    "            return table\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {attempt + 1}: {ext}\")\n",
    "            attempt += 1\n",
    "            driver.quit()\n",
    "            \n",
    "            if attempt + 1 < max_retries:\n",
    "                print(f\"Retrying... ({attempt + 1}/{max_retries})\")\n",
    "                driver.quit()\n",
    "\n",
    "            else:\n",
    "                print(f\"Max retries reached. Moving to the next URL.\")\n",
    "                break\n",
    "    \n",
    "    driver.quit()\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET ASIAN HANDICAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AH(url, ext, title, max_retries=100):\n",
    "\n",
    "    all_row_data = []\n",
    "    attempt = 0\n",
    "\n",
    "    while attempt < max_retries:\n",
    "\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"chrome-version=132\")\n",
    "\n",
    "        driver = uc.Chrome(options=chrome_options)\n",
    "        driver.get(url + ext)\n",
    "        try:\n",
    "\n",
    "            WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[contains(@class, 'relative flex flex-col')]\"))\n",
    "            )\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            ah_elements = soup.find_all(\"div\", class_=\"relative flex flex-col\")\n",
    "            \n",
    "            row_data = {}\n",
    "\n",
    "            for element in ah_elements:\n",
    "                ah_text = element.find(\"div\", class_=\"flex w-full items-center justify-start pl-3 font-bold text-[#2F2F2F]\").find_all(\"p\")\n",
    "                ah = ah_text[0].text.strip()\n",
    "                odds_containers = element.find_all(\"div\", class_=\"flex-center border-black-main min-w-[60px] max-w-[60px] flex-col gap-1 border-l border-opacity-10\")\n",
    "                \n",
    "                o_odds = odds_containers[0].find(\"p\").text.strip()\n",
    "                t_odds = odds_containers[1].find(\"p\").text.strip()\n",
    "\n",
    "                row_data[f\"{ah}_{title}_1\"] = o_odds\n",
    "                row_data[f\"{ah}_{title}_2\"] = t_odds\n",
    "\n",
    "            if row_data:\n",
    "                all_row_data.append(row_data)\n",
    "\n",
    "            if not row_data:\n",
    "                print(f\"Warning: No AH{title} or odds found on attempt {attempt + 1}. Retrying...\")\n",
    "                attempt += 1\n",
    "                driver.quit()\n",
    "                continue\n",
    "\n",
    "            return all_row_data\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {attempt + 1}: AH{title}\")\n",
    "            attempt += 1\n",
    "            driver.quit()\n",
    "            \n",
    "            if attempt + 1 < max_retries:\n",
    "                print(f\"Retrying... ({attempt + 1}/{max_retries})\")\n",
    "                driver.quit()\n",
    "\n",
    "            else:\n",
    "                print(f\"Max retries reached. Moving to the next URL.\")\n",
    "                break\n",
    "    \n",
    "    driver.quit()\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get GameLink Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_odds(game_link):\n",
    "\n",
    "    \"\"\"Fetch odds for a each game.\"\"\"\n",
    "    try:\n",
    "        _1X2FT = get_1x2_odds(game_link,'1X2FT', \"#1X2;2\")\n",
    "        _1X2H1 = get_1x2_odds(game_link,'1X2H1', \"#1X2;3\")\n",
    "        _1X2H2 = get_1x2_odds(game_link,'1X2H2', \"#1X2;4\")\n",
    "        DCFT = get_1x2_odds(game_link,'DCFT', \"#double;2\")\n",
    "        DCH1 = get_1x2_odds(game_link,'DCH1', \"#double;3\")\n",
    "        DCH2 = get_1x2_odds(game_link,'DCH2', \"#double;4\")\n",
    "        HTFT = get_HTFT(game_link)\n",
    "        DNBFT = get_1_2_odds(game_link,'DNBFT', \"#dnb;2\")\n",
    "        DNBH1 = get_1_2_odds(game_link,'DNBH1', \"#dnb;3\")\n",
    "        DNBH2 = get_1_2_odds(game_link,'DNBH2', \"#dnb;4\")\n",
    "        BTSFT = get_1_2_odds(game_link,'BTSFT', \"#bts;2\")\n",
    "        BTSH1 = get_1_2_odds(game_link,'BTSH1', \"#bts;3\")\n",
    "        BTSH2 = get_1_2_odds(game_link,'BTSH2', \"#bts;4\")\n",
    "        OUFT = get_OU(game_link, \"#over-under;2\", 'FT')\n",
    "        OUH1 = get_OU(game_link, \"#over-under;3\", 'H1')\n",
    "        OUH2 = get_OU(game_link, \"#over-under;4\", 'H2')\n",
    "        CSFT = get_CS(game_link, '#cs;2', 'FT')\n",
    "        CSH1 = get_CS(game_link, '#cs;3', 'H1')\n",
    "        CSH2 = get_CS(game_link, '#cs;4', 'H2')\n",
    "        AHFT = get_AH(game_link, \"#ah;2\", 'FT')\n",
    "        AHH1 = get_AH(game_link, \"#ah;3\", 'H1')\n",
    "        AHH2 = get_AH(game_link, \"#ah;4\", 'H2')\n",
    "\n",
    "        game = { 'URL' : game_link}\n",
    "\n",
    "        df = {\n",
    "            **game,\n",
    "            **_1X2FT[0], \n",
    "            **_1X2H1[0],\n",
    "            **_1X2H2[0],\n",
    "            **DCFT[0],\n",
    "            **DCH1[0],\n",
    "            **DCH2[0],\n",
    "            **HTFT[0],\n",
    "            **DNBFT[0],\n",
    "            **DNBH1[0],\n",
    "            **DNBH2[0],\n",
    "            **BTSFT[0],\n",
    "            **BTSH1[0],\n",
    "            **BTSH2[0],\n",
    "            **OUFT[0],\n",
    "            **OUH1[0],\n",
    "            **OUH2[0],\n",
    "            **CSFT,\n",
    "            **CSH1,\n",
    "            **CSH2,\n",
    "            **AHFT[0],\n",
    "            **AHH1[0],\n",
    "            **AHH2[0]}\n",
    "\n",
    "        df = pd.DataFrame([df])\n",
    "\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching odds for {game_link}: {e} get_game_odds0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Odds DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_odds_df(game_data, save_interval=100, output_filename='odds_data.csv', resume=False):\n",
    "    game_links = game_data['URL'].to_list()\n",
    "    all_odds = []\n",
    "    all_columns = set()\n",
    "    \n",
    "    base_column_order = [\n",
    "        'URL',\n",
    "        '1X2FT_1', '1X2FT_X', '1X2FT_2',\n",
    "        '1X2H1_1', '1X2H1_X', '1X2H1_2',\n",
    "        '1X2H2_1', '1X2H2_X', '1X2H2_2',\n",
    "        'DCFT_1', 'DCFT_X', 'DCFT_2',\n",
    "        'DCH1_1', 'DCH1_X', 'DCH1_2',\n",
    "        'DCH2_1', 'DCH2_X', 'DCH2_2',\n",
    "        'H_H', 'H_D', 'H_A',\n",
    "        'D_H', 'D_D', 'D_A',\n",
    "        'A_H', 'A_D', 'A_A',\n",
    "        'DNBFT_1', 'DNBFT_2',\n",
    "        'DNBH1_1', 'DNBH1_2',\n",
    "        'DNBH2_1', 'DNBH2_2',\n",
    "        'BTSFT_1', 'BTSFT_2',\n",
    "        'BTSH1_1', 'BTSH1_2',\n",
    "        'BTSH2_1', 'BTSH2_2',\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    start_idx = 0\n",
    "    if resume and os.path.exists(output_filename):\n",
    "       \n",
    "        print(f\"Loading existing data from {output_filename}...\")\n",
    "        existing_data = pd.read_csv(output_filename)\n",
    "        start_idx = len(existing_data)\n",
    "        all_odds = [existing_data]  \n",
    "    \n",
    "    for i, game in enumerate(game_links[start_idx:], start=start_idx+1):\n",
    "        try:\n",
    "            game_odds = get_game_odds(game)\n",
    "            if not game_odds.empty:\n",
    "                all_columns.update(game_odds.columns) \n",
    "                all_odds.append(game_odds) \n",
    "            print(f\"Completed game #{i} of {len(game_links)}\")\n",
    "            \n",
    "            # Save periodically\n",
    "            if i % save_interval == 0:\n",
    "                print(f\"Saving progress at game #{i}...\")\n",
    "                df_all_odds = pd.concat(all_odds, ignore_index=True)\n",
    "                df_all_odds.to_csv(output_filename, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing game #{i}:\")\n",
    "    \n",
    "    \n",
    "    if all_odds:\n",
    "        df_all_odds = pd.concat(all_odds, ignore_index=True)\n",
    "        df_all_odds.to_csv(output_filename, index=False)\n",
    "        print(f\"Final data saved to {output_filename}\")\n",
    "    \n",
    "    # Process columns\n",
    "    if all_odds:\n",
    "        all_odds_aligned = []\n",
    "\n",
    "        # Over/Under Columns\n",
    "        over_under_columns = [col for col in all_columns if 'Over/Under' in col]\n",
    "        over_under_columns_sorted = sorted(over_under_columns, key=lambda x: (\n",
    "            re.search(r'(FT|H1|H2)', x).group(),\n",
    "            float(re.search(r'(\\+?\\d+\\.\\d+|\\d+)', x).group()), \n",
    "            '_Under' in x ))\n",
    "\n",
    "        # Correct Score Columns\n",
    "        CS_columns = [col for col in all_columns if 'CS' in col]\n",
    "        CS_columns_sorted = sorted(CS_columns, key=lambda x: (\n",
    "            re.search(r'(FT|H1|H2)', x).group(),\n",
    "            *map(int, re.search(r'(\\d+):(\\d+)', x).groups())\n",
    "        ))\n",
    "\n",
    "        # Asian Handicap Columns\n",
    "        AH_columns = [col for col in all_columns if 'AH' in col]\n",
    "        AH_columns_sorted = sorted(AH_columns, key=lambda x: (\n",
    "            re.search(r'(FT|H1|H2)', x).group(),\n",
    "            *map(int, re.search(r'(\\d+)', x).groups())\n",
    "        ))\n",
    "\n",
    "        dynamic_column_order = base_column_order + over_under_columns_sorted + CS_columns_sorted + AH_columns_sorted \n",
    "\n",
    "        for df in all_odds:\n",
    "            df_aligned = df.reindex(columns=dynamic_column_order)\n",
    "            all_odds_aligned.append(df_aligned)\n",
    "\n",
    "        return pd.concat(all_odds_aligned, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Code run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data = get_upcoming_games(leagues)\n",
    "odds_df = build_odds_df(game_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(odds_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
